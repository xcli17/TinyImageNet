{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['resnext', 'wideresnet', 'densenet']\n",
    "train_file = \"prediction_{}_train.pkl\"\n",
    "val_file = \"prediction_{}_val.pkl\"\n",
    "test_file = \"prediction_{}.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depackage(result):\n",
    "    result_tp = []\n",
    "    for i in range(len(result)):\n",
    "        labels = result[i][0]\n",
    "        outputs = result[i][1]\n",
    "        for j in range(len(labels)):\n",
    "            result_tp.append((labels[j], outputs[j]))\n",
    "    return result_tp\n",
    "\n",
    "def depackage_test(result):\n",
    "    result_dp = {}\n",
    "    for key, val in result.items():\n",
    "        for i in range(len(key)):\n",
    "            result_dp[key[i]] = val[i]\n",
    "    return result_dp\n",
    "\n",
    "def read_and_combine_data(models, mode):\n",
    "    data = {}\n",
    "    if mode in ['train', 'val']:\n",
    "        if mode == 'train':\n",
    "            file_template = train_file\n",
    "        else:\n",
    "            file_template = val_file\n",
    "        X = []\n",
    "        y = []\n",
    "        for model in models:\n",
    "            data[model] = depackage(pickle.load(open(\"./\" + model + '/' + file_template.format(model), \"rb\")))\n",
    "        for i in range(len(data[models[0]])):\n",
    "            assert(data[models[0]][i][0] == data[models[1]][i][0])\n",
    "            y.append(data[models[0]][i][0])\n",
    "            outputs = []\n",
    "            for model in models:\n",
    "                outputs.append(data[model][i][1])\n",
    "            X.append(np.concatenate(outputs, axis=0))\n",
    "        X = np.array(X)\n",
    "        return X, np.array(y)\n",
    "    else:\n",
    "        file_template = test_file\n",
    "        for model in models:\n",
    "            data[model] = depackage_test(pickle.load(open(\"./\" + model + '/' + file_template.format(model), \"rb\")))\n",
    "        res_dict = {}\n",
    "        for key in data[models[0]]:\n",
    "            outputs = []\n",
    "            for model in models:\n",
    "                outputs.append(data[model][key])\n",
    "            res_dict[key] = np.concatenate(outputs, axis=0)\n",
    "        return res_dict\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=1, keepdims=True)\n",
    "    xexp = np.exp(x)\n",
    "    row_sum = xexp.sum(axis=1, keepdims=True)\n",
    "    x = xexp / row_sum\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = read_and_combine_data(models, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = read_and_combine_data(models, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_and_combine_data(models, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    X_train[:, i*100:(i+1)*100] = softmax(X_train[:, i*100:(i+1)*100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(300,)))\n",
    "model.add(keras.layers.Dense(600, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [0.475, 0.425, 0.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(result, weights):\n",
    "    X = []\n",
    "    label = []\n",
    "    for key, value in data.items():\n",
    "        X.append(value)\n",
    "        label.append(key)\n",
    "    # X=softmax(np.array(X))\n",
    "    X = np.array(X)\n",
    "    sumr = X[:, 0:100] * weights[0]\n",
    "    for i in range(1, len(weights)):\n",
    "        sumr += X[:, 100*i:100*(i+1)] * weights[i]\n",
    "    sumr = np.argmax(sumr, axis=1)\n",
    "    return dict(zip(label, sumr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fusion = fusion(data, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = []\n",
    "# label = []\n",
    "# for key, value in data.items():\n",
    "#     X.append(value)\n",
    "#     label.append(key)\n",
    "# X=softmax(np.array(X))\n",
    "# preds = np.argmax(model.predict(X),axis=1)\n",
    "# result_fusion = dict(zip(label, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([result_fusion]).transpose().reset_index(drop=False)\n",
    "df.columns = ['Id', 'Category']\n",
    "df.loc[:, 'Id']=df['Id'].apply(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission_fusion.csv\", index=False)"
   ]
  }
 ]
}