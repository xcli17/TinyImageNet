{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_gpu = torch.cuda.is_available()\n",
    "if cuda_gpu:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu:0\")\n",
    "nclass = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to C:\\Users\\70659/.cache\\torch\\hub\\checkpoints\\vgg19_bn-c79401a0.pth\n",
      "100%|██████████| 548M/548M [00:49<00:00, 11.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vgg19_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnext101_32x8d(pretrained=True)\n",
    "model.fc = nn.Linear(2048, 100, bias=True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in model.named_parameters():\n",
    "    if \"fc\" not in name and \"classifier\" not in name:\n",
    "        value.requires_grad = False\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "SAVE_EPOCH = 3\n",
    "VAL_EPOCH = 6\n",
    "verbose = 500\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize([124,117,104],[58.4,57.1,57.4])\n",
    "    ])\n",
    "\n",
    "class ImageNetData(Dataset):\n",
    "    \n",
    "    def __init__(self, path, info, nclass):\n",
    "        self.path = path\n",
    "        info_path = os.path.join(path, info)\n",
    "        f = open(info_path)\n",
    "        self.data = f.read().splitlines()\n",
    "        self.transforms = data_transformer\n",
    "        self.nclass = nclass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.path, self.data[index].split(' ')[0]))\n",
    "        img = self.transforms(img)\n",
    "        label = self.data[index].split(' ')[1]\n",
    "        label = int(label)\n",
    "#         one_hot = np.zeros(self.nclass, dtype=np.int)\n",
    "#         one_hot[label] = 1\n",
    "        return (img, label)\n",
    "\n",
    "path = \"D:/课程文件/大四上/深度学习导论/作业/5/TinyImageNet/TinyImageNet\"\n",
    "train_info_path = path + '/train.txt'\n",
    "val_info_path = path + '/val.txt'\n",
    "train_set = ImageNetData(path, \"train.txt\", nclass)\n",
    "val_set = ImageNetData(path, \"val.txt\", nclass)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=BATCH_SIZE)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckptpath = \"./ckpts/\"\n",
    "ckpts = sorted([x for x in os.listdir(ckptpath) if x.endswith(\".ckpt\")])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "lr_reduct = lambda epochs: 0.5 ** (epochs // 20)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_reduct)\n",
    "if len(ckpts) >= 1:\n",
    "    state_dicts = torch.load(ckptpath+ckpts[-1])\n",
    "    model.load_state_dict(state_dicts['model'])\n",
    "    optimizer.load_state_dict(state_dicts['optimizer'])\n",
    "    scheduler.load_state_dict(state_dicts['scheduler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"resnext_fc_trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "Train: 500/1852 - Average Time: 1.4833536701202392\n",
      "Train: 1000/1852 - Average Time: 1.4715055954456329\n",
      "Train: 1500/1852 - Average Time: 1.4613547286987305\n",
      "End of Train Epoch: 1 - Average Time: 1.4534766398547279\n",
      "Train loss : 1.6001149354096236 Train accuracy : 0.7970062395008414\n",
      "44m 52s\n",
      "Epoch 2/30\n",
      "Train: 500/1852 - Average Time: 1.4283644976615906\n",
      "Train: 1000/1852 - Average Time: 1.4351588249206544\n",
      "Train: 1500/1852 - Average Time: 1.4417788144747417\n",
      "End of Train Epoch: 2 - Average Time: 1.447733206058939\n",
      "Train loss : 1.5348703046741676 Train accuracy : 0.8036657067434625\n",
      "44m 41s\n",
      "Epoch 3/30\n",
      "Train: 500/1852 - Average Time: 1.4582891778945923\n",
      "Train: 1000/1852 - Average Time: 1.4674520030021667\n",
      "Train: 1500/1852 - Average Time: 1.4695797085762023\n",
      "End of Train Epoch: 3 - Average Time: 1.469803229650205\n",
      "Train loss : 1.5037949961865598 Train accuracy : 0.8079253659707255\n",
      "45m 23s\n",
      "Epoch 4/30\n",
      "Train: 500/1852 - Average Time: 1.4746369490623474\n",
      "Train: 1000/1852 - Average Time: 1.474351241827011\n",
      "Train: 1500/1852 - Average Time: 1.4730799171129862\n",
      "End of Train Epoch: 4 - Average Time: 1.476363812872967\n",
      "Train loss : 1.5215755893082457 Train accuracy : 0.8079953603711741\n",
      "45m 34s\n",
      "Epoch 5/30\n",
      "Train: 500/1852 - Average Time: 1.4725464935302734\n",
      "Train: 1000/1852 - Average Time: 1.4793850545883178\n",
      "Train: 1500/1852 - Average Time: 1.4752055848439534\n",
      "End of Train Epoch: 5 - Average Time: 1.4754627303222343\n",
      "Train loss : 1.4627848141474677 Train accuracy : 0.8136049116070759\n",
      "45m 33s\n",
      "Epoch 6/30\n",
      "Train: 500/1852 - Average Time: 1.4805502610206605\n",
      "Train: 1000/1852 - Average Time: 1.4830413420200348\n",
      "Train: 1500/1852 - Average Time: 1.484396812915802\n",
      "End of Train Epoch: 6 - Average Time: 1.479530227750733\n",
      "Train loss : 1.4682022331938245 Train accuracy : 0.8149848012159089\n",
      "Val   loss : 23.723940221212242 Val   accuracy : 0.12405416168857031\n",
      "50m 20s\n",
      "Epoch 7/30\n",
      "Train: 500/1852 - Average Time: 1.4672412757873534\n",
      "Train: 1000/1852 - Average Time: 1.474477637529373\n",
      "Train: 1500/1852 - Average Time: 1.4735474996566773\n",
      "End of Train Epoch: 7 - Average Time: 1.4737687351636701\n",
      "Train loss : 1.4590423733446563 Train accuracy : 0.8149348052155889\n",
      "45m 29s\n",
      "Epoch 8/30\n",
      "Train: 500/1852 - Average Time: 1.4844118442535401\n",
      "Train: 1000/1852 - Average Time: 1.4769036509990692\n",
      "Train: 1500/1852 - Average Time: 1.4781851507822672\n",
      "End of Train Epoch: 8 - Average Time: 1.4770048259401425\n",
      "Train loss : 1.4339925456333495 Train accuracy : 0.818074554035682\n",
      "45m 35s\n",
      "Epoch 9/30\n",
      "Train: 500/1852 - Average Time: 1.4668344016075134\n",
      "Train: 1000/1852 - Average Time: 1.4681645355224608\n",
      "Train: 1500/1852 - Average Time: 1.4689198223749798\n",
      "End of Train Epoch: 9 - Average Time: 1.4702017708936983\n",
      "Train loss : 1.4221280814021762 Train accuracy : 0.8213242940564788\n",
      "45m 24s\n",
      "Epoch 10/30\n",
      "Train: 500/1852 - Average Time: 1.4708458948135377\n",
      "Train: 1000/1852 - Average Time: 1.468622802734375\n",
      "Train: 1500/1852 - Average Time: 1.4711750723520916\n",
      "End of Train Epoch: 10 - Average Time: 1.4713568818749414\n",
      "Train loss : 1.4086368265390783 Train accuracy : 0.8225541956643504\n",
      "45m 25s\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-286b90444a79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for epochs in range(1, EPOCHS + 1):\n",
    "        print('Epoch {}/{}'.format(epochs, EPOCHS))\n",
    "        start_time = time.time()\n",
    "        running_train_loss = []\n",
    "        running_train_acc = []\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs = data[0].to(device)\n",
    "            targets = data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = outputs.argmax(axis=1)\n",
    "            running_train_loss.append(float(loss))\n",
    "            running_train_acc.append(float((pred==targets).sum()) / BATCH_SIZE)\n",
    "            if verbose > 0 and (i + 1) % verbose == 0:\n",
    "                print(\"Train: {}/{} - Average Time: {}\".format(i + 1, len(train_loader), (time.time()-start_time) / (i + 1)))\n",
    "        print(\"End of Train Epoch: {} - Average Time: {}\".format(epochs, (time.time() - start_time) / (i + 1)))\n",
    "        # 周期性清除CUDA缓存\n",
    "        torch.cuda.empty_cache()\n",
    "        if epochs % SAVE_EPOCH == 0:\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                       'optimizer': optimizer.state_dict(), \n",
    "                       'scheduler': scheduler.state_dict()},\n",
    "                       ckptpath + \"model_{}.ckpt\".format(int(datetime.datetime.now().timestamp())))\n",
    "        if epochs % VAL_EPOCH == 0:\n",
    "            running_val_loss = []\n",
    "            running_val_acc = []\n",
    "            for i, data in enumerate(val_loader):\n",
    "                inputs=data[0].to(device)\n",
    "                targets=data[1].to(device)\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_func(outputs, targets)\n",
    "                    pred = outputs.argmax(axis=1)\n",
    "                    running_val_loss.append(float(loss))\n",
    "                    running_val_acc.append(float((pred==targets).sum()) / BATCH_SIZE)\n",
    "                if verbose > 0 and(i + 1) % verbose == 0:\n",
    "                    print(\"Val: {}/{}\".format(i + 1, len(val_loader)))\n",
    "        \n",
    "        scheduler.step()    \n",
    "        train_loss.append(sum(running_train_loss) / len(running_train_loss))\n",
    "        train_acc.append(sum(running_train_acc) / len(running_train_acc))\n",
    "        duration = time.time() - start_time\n",
    "        print('Train loss : {} Train accuracy : {}'.format(train_loss[-1], train_acc[-1]))\n",
    "        if epochs % VAL_EPOCH == 0:\n",
    "            val_loss.append(sum(running_val_loss) / len(running_val_loss))\n",
    "            val_acc.append(sum(running_val_acc) / len(running_val_acc))\n",
    "            print('Val   loss : {} Val   accuracy : {}'.format(val_loss[-1], val_acc[-1]))\n",
    "        print('{:.0f}m {:.0f}s'.format(duration // 60, duration % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model': model.state_dict(), \n",
    "            'optimizer': optimizer.state_dict(), \n",
    "            'scheduler': scheduler.state_dict()},\n",
    "            ckptpath + \"model_{}.ckpt\".format(int(datetime.datetime.now().timestamp())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'model_1604847063.ckpt'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "ckpts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=2020, tm_mon=11, tm_mday=9, tm_hour=7, tm_min=22, tm_sec=13, tm_wday=0, tm_yday=314, tm_isdst=0)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "time.localtime(1604877733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetDataTest(Dataset):\n",
    "    def __init__(self, path, info, nclass):\n",
    "        self.path = path\n",
    "        info_path = os.path.join(path, info)\n",
    "        f = open(info_path)\n",
    "        self.data = f.read().splitlines()\n",
    "        self.transforms = data_transformer\n",
    "        self.nclass = nclass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.path, self.data[index].split(' ')[0]))\n",
    "        img = self.transforms(img)\n",
    "#         one_hot = np.zeros(self.nclass, dtype=np.int)\n",
    "#         one_hot[label] = 1\n",
    "        return (self.data[index], img)\n",
    "\n",
    "test_info_path = path + '/test.txt'\n",
    "test_set = ImageNetDataTest(path, \"test.txt\", nclass)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-41421fc64dc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test: {}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "names = []\n",
    "preds = []\n",
    "preds_val = {}\n",
    "for i, data in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        name = data[0]\n",
    "        inputs = data[1].to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds_val[name] = outputs.cpu().numpy()\n",
    "        pred = outputs.argmax(axis=1).squeeze()\n",
    "        names.extend(name)\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(\"Test: {}/{}\".format(i + 1, len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([names,preds]).transpose()\n",
    "df.columns = ['Id', 'Category']\n",
    "df.loc[:, 'Id']=df['Id'].apply(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission_resnext.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"prediction_resnext.pkl\", \"wb\")\n",
    "pickle.dump(preds_val, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(loader, fname, verbose, total):\n",
    "    preds_val = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader):\n",
    "            inputs = data[0].to(device)\n",
    "            targets = data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds_val.append((targets.cpu().numpy(), outputs.cpu().numpy()))\n",
    "            if (i + 1) % verbose == 0:\n",
    "                print(\"Predict: {}/{}\".format(i + 1, total))\n",
    "            torch.cuda.empty_cache()\n",
    "    f = open(fname, \"wb\")\n",
    "    pickle.dump(preds_val, f)\n",
    "    f.close()\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predict: 100/1562\n",
      "Predict: 200/1562\n",
      "Predict: 300/1562\n",
      "Predict: 400/1562\n",
      "Predict: 500/1562\n",
      "Predict: 600/1562\n",
      "Predict: 700/1562\n",
      "Predict: 800/1562\n",
      "Predict: 900/1562\n",
      "Predict: 1000/1562\n",
      "Predict: 1100/1562\n",
      "Predict: 1200/1562\n",
      "Predict: 1300/1562\n",
      "Predict: 1400/1562\n",
      "Predict: 1500/1562\n"
     ]
    }
   ],
   "source": [
    "getPrediction(train_loader, \"prediction_resnext_train.pkl\", 100, int(len(train_set)/64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predict: 100/156\n"
     ]
    }
   ],
   "source": [
    "getPrediction(val_loader, \"prediction_resnext_val.pkl\", 100, int(len(val_set)/64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}